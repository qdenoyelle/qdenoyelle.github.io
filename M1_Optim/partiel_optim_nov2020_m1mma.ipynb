{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A remplir (mettre aussi votre nom dans le titre du fichier)\n",
    "Nom : \n",
    "Prénom : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Partiel d'optimisation M1 MMA du 16/11/2020. Durée 2h</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tous les documents du cours sont autorisés. Uploadez ce fichier ainsi que vos documents annexes de réponses (si vous en avez) sur Moodle avant l'heure limite de rendu.\n",
    "Pensez à :\n",
    "<ul>\n",
    "    <li>sauvegarder régulièrement ce document (disquette en haut à gauche),</li>\n",
    "    <li>n'attendez pas la dernière minute pour remettre vos fichiers. Aucun dépassement ne sera autorisé (sauf cas exceptionnel).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "params = {'tex.usetex': True}\n",
    "\n",
    "# Paramètres pour générer les données du problème.\n",
    "t = 2*np.pi*np.random.rand()\n",
    "u = np.array([np.cos(t), np.sin(t)])\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On considère donnée une famille de couples $((x_i,y_i))_{0\\leq i\\leq M-1}$ où pour tout $i$, $x_i$ est un point du plan $\\mathbb{R}^2$ et $y_i\\in\\{-1,1\\}$ défini l'appartenance de $x_i$ à une des deux classes représentées par les nombres $-1$ et $1$.\n",
    "\n",
    "Les couples $((x_i,y_i))_{0\\leq i\\leq M-1}$ sont une réalisation d'un échantillon de taille $M$ de la variable aléatoire $(X,Y)$ à valeurs dans $\\mathbb{R}^2\\times\\{-1,1\\}$, c'est-à-dire une réalisation de $M$ variables aléatoires indépendantes $(X_i,Y_i)$ de même loi que le couple $(X,Y)$.\n",
    "\n",
    "Une réalisation de la variable $(X,Y)$ est donnée par la fonction $\\mbox{genererCouple}$ suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genererCouple():\n",
    "    # renvoie une réalisation de la variable aléatoire (X,Y)\n",
    "    if np.random.rand() < 0.5:\n",
    "        x, y = 2.*np.random.randn(2) + 3*u, -1 # bleu\n",
    "    else:\n",
    "        x, y = 2.*np.random.randn(2) - 3*u, 1 # rouge\n",
    "    return [x, y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La case suivante génère les données fixées du problème $((x_i,y_i))_{0\\leq i\\leq M-1}$ et les affiches graphiquement. La population de type \"-1\" (c'est-à-dire les $x_i$ tels que $y_i=-1$) est affichée en bleu et celle de type \"1\" en rouge. Les $x_i$ sont stockés dans un vecteur $\\mbox{xv}$ et les $y_i$ dans un vecteur $\\mbox{yv}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 1000\n",
    "xv, yv = np.zeros((M, 2)), np.zeros(M)\n",
    "for i in range(M):\n",
    "    xv[i, :], yv[i] = genererCouple() # on stocke les données ((x_i, y_i))_i\n",
    "\n",
    "# affichage\n",
    "plt.figure(figsize = (6, 6))\n",
    "for i in range(M):\n",
    "    if yv[i] == 1: # si x_i est de type 1 alors on affiche un point rouge\n",
    "        plt.plot(xv[i,0], xv[i, 1], linestyle = \"none\", Marker = '.', color = \"red\")\n",
    "    else:\n",
    "        plt.plot(xv[i,0], xv[i, 1], linestyle = \"none\", Marker = '.', color = \"blue\")\n",
    "plt.title(r\"Représentation des $x_i$ (bleu quand $y_i=-1$, rouge sinon)\")\n",
    "plt.axis(\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de ce sujet est, à partir des données d'entraînement ci-dessus $((x_i,y_i))_{0\\leq i\\leq M-1}$, d'apprendre à prédire, sachant uniquement une nouvelle valeur $x\\in\\mathbb{R}^2$ de $X$, la valeur du $y$ associé (c'est-à-dire la couleur du point $x$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cela on va déterminer la meilleur droite passant par $(0,0)$ qui sépare les deux populations (rouge et bleu) des données.\n",
    "\n",
    "Une droite qui passe par $(0,0)$ a pour équation $f(x) = 0$ où $f : x\\in\\mathbb{R}^2 \\mapsto \\alpha_0 x_0 + \\alpha_1 x_1$ avec $\\alpha = (\\alpha_0, \\alpha_1)\\in\\mathbb{R}^2$ un vecteur normal de la droite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Déterminer le gradient de $f$ en $x$. Commenter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Afficher les lignes de niveau de la fonction $\\mbox{f}$ définie ci dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [1, -1] # vecteur normal à la droite\n",
    "def f(x):\n",
    "    return x[0]*alpha[0] + x[1]*alpha[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) A quoi correspond sur le graphe ci-dessus la droite de vecteur normal $\\mbox{alpha}$ passant par $(0,0)$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée est donc de trouver la meilleure orientation (paramétrée par $\\alpha$) des lignes de niveau de $f$ de sorte qu'un $x$ (venant de $X$) qui se situerait dans le demi-plan où $f$ prend des valeurs négatives, respectivement positives, serait associé à la prédiction $-1$ (couleur bleu), respectivement $1$ (couleur rouge), pour $y$.\n",
    "\n",
    "Pour déterminer cette meilleure orientation $\\alpha\\in\\mathbb{R}^2$, nous allons chercher à résoudre le problème d'optimisation suivant : \n",
    "$$\n",
    "    \\min_{\\alpha\\in\\mathbb{R}^2} \\ F(\\alpha), \\quad \\mbox{ où } F:\\alpha\\in\\mathbb{R}^2\\mapsto \\lambda \\|\\alpha\\|_2^2 + \\frac1M \\sum_{i=0}^{M-1} \\log(1 + e^{-y_i (\\alpha_0 x_{i,0} + \\alpha_1 x_{i,1})}),\n",
    "$$\n",
    "où $\\lambda > 0$ est un paramètre fixé et les $x_i = (x_{i,0}, x_{i,1})\\in\\mathbb{R}^2$ et $y_i\\in\\{-1,1\\}$ sont les données du problème. Ici $\\log$ représente le logarithme népérien.\n",
    "\n",
    "(On ne discutera pas dans ce sujet de pourquoi on choisit ce $F:\\alpha\\in\\mathbb{R}^2\\to\\mathbb{R}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Etude théorique du problème d'optimisation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On prendra soin à bien justifier les réponses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Démontrer que si $g:\\mathbb{R}^m\\to\\mathbb{R}$ est convexe et $f:\\mathbb{R}^n\\to\\mathbb{R}$ est telle que $f(x) = g(Ax + b)$ avec $A\\in\\mathcal{M}_{m,n}(\\mathbb{R})$ et $b\\in\\mathbb{R}^m$ alors $f$ est convexe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Démontrer que $F$ est strictement convexe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Que peut-on en déduire sur la matrice Hessienne de $F$ en $\\alpha\\in\\mathbb{R}^2$ quelconque ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Démontrer que $F$ est coercive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Démontrer que $F$ admet un unique minimum global que l'on notera $\\alpha^*$ dans la suite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Est-ce que $F$ peut admettre un maximum local ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Résolution numérique du problème d'optimisation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Ecrire en Python une fonction $\\mbox{F}$ prenant en argument $\\mbox{alpha}$ et représentant la fonction objective. Le paramètre $\\lambda$ est fixé à $0.05$. (Indication : pour une implémentation rapide du vecteur $(\\alpha_0 x_{i,0} + \\alpha_1 x_{i,1})_{0\\leq i \\leq M-1}$, on pourra utiliser la commande $\\mbox{np.dot(xv, alpha)}$ plutôt que d'écrire une boucle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "λ = 0.05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Afficher les lignes de niveau de $F$ sur le domaine $[-3, 2]\\times[-3, 0.5]$. (Indication : pour stocker ici les valeurs prises par $F$ dans une matrice Z, on fera une double boucle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) Calculer le gradient de $F$ en $\\alpha\\in\\mathbb{R}^2$ : $\\nabla F(\\alpha)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Ecrire en Python une fonction $\\mbox{gradF}$ prenant en argument $\\mbox{alpha}$ et représentant le gradient de $F$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valider cette case pour vérifier que votre implémentation du gradient de F est correcte\n",
    "alpha = np.random.rand(2)\n",
    "epsilon = 1e-8\n",
    "print(\"Cette quantité doit être de l\\'ordre de 1e-8 : \", np.linalg.norm(gradF(alpha) - np.array([(F(alpha + epsilon*np.array([1,0])) - F(alpha))/(epsilon), (F(alpha + epsilon*np.array([0,1])) - F(alpha))/(epsilon)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) Ecrire en Python une fonction $\\mbox{gradientPasConstant}$ prenant en argument $\\mbox{gradF}$, le gradient de $F$, $\\mbox{alpha_0}$, un point de départ, $\\mbox{tau}$, un pas de descente, $\\mbox{epsilon}$, une tolérance, et $\\mbox{Niter}$, un nombre d'itérations maximum. La fonction reverra la valeur du dernier itéré ainsi que la liste des itérés successifs. On fera attention à évaluer la fonction $\\mbox{gradF}$ le moins de fois possible.\n",
    "\n",
    "La fonction $\\mbox{gradientPasConstant}$ correspond à un algorithme de descente où à chaque itération la direction de descente est donnée par moins le gradient (en l'itéré courant) et où le pas de descente est choisi constant valant $\\mbox{tau}>0$. Cette méthode s'appelle la méthode de la descente de gradient à pas constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la suite, on prendra $\\mbox{tau}=0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) Illustrer la converge de l'algorithme en utilisant la fonction $\\mbox{plt.semilogy}$. (Indication : on utilisera d'abord l'algorithme avec une tolérance faible, par exemple $10^{-8}$, et on utilisera l'approximée obtenu comme limite de référence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16) De quel type de convergence s'agit-il ? Justifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17) Superposer la trajectoire obtenue via l'algorithme de descente avec les lignes de niveau de $F$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18) Définir la fonction $\\mbox{f}$ comme en 2) qui cette fois correspond au $\\mbox{alpha}$ optimal trouvé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19) Superposer les lignes de niveau de $\\mbox{f}$ au graphe affichant les deux populations (rouge, bleu) de points $x_i$ vu au début du sujet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20) Ecrire une fonction qui renvoie la prédiction de $y$ (\"$-1$\" ou \"$1$\") en fonction d'un $x$ donné. On pensera à utiliser la fonction $\\mbox{np.sign}$. Comparer la prédiction à la réalité en utilisant la fonction $\\mbox{genererCouple}$ (qui renvoie un couple (x,y) réalisation de (X,Y)) de l'énoncé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21) Déterminer le taux de succès de la méthode de prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Etude de l'influence de $\\lambda$</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22) Décrire l'impact de $\\lambda$ sur la vitesse de convergence de l'algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23) Comment évoluent les lignes de niveau de $F$ en fonction de $\\lambda$ ? Donner ensuite une explication qualitative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24) Comment évolue la performance de prédiction en fonction de $\\lambda$. Expliquer ce comportement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25) On considère $G(x) = \\lambda \\|x\\|_2^2$. Donner et démontrer une condition nécessaire et suffisante sur le pas de descente $\\tau>0$ pour que la suite produite par la méthode de la descente de gradient à pas fixe (décrite précédemment) converge vers l'unique minimum global de $G$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
